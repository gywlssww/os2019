{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from pprint import pprint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score,accuracy_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_train_df=pd.read_csv('../data/mixed_train_data.csv', delimiter='\\t')\n",
    "cleaned_test_df=pd.read_csv('../data/mixed_test_data.csv', delimiter='\\t')\n",
    "X_train_doc_list=[eval(doc_str) for doc_str in cleaned_train_df['doc_txt'].tolist()]\n",
    "X_test_doc_list=[eval(doc_str) for doc_str in cleaned_test_df['doc_txt'].tolist()]\n",
    "\n",
    "X_train_doc_list=[\" \".join(doc) for doc in X_train_doc_list]\n",
    "X_test_doc_list=[\" \".join(doc) for doc in X_test_doc_list]\n",
    "\n",
    "y_train=cleaned_train_df['smk_status'].tolist()\n",
    "y_test=cleaned_test_df['smk_status'].tolist()\n",
    "\n",
    "tfidf_paths=glob.glob(\"../data/doc_vectors/tfidf/*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear SVM Testing CV=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_uni_features_None_analyzer_word.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6606    0.6372    0.6486       226\n",
      "           2     0.7192    0.7449    0.7318       196\n",
      "           3     0.8000    0.0367    0.0702       109\n",
      "           4     0.7447    0.9345    0.8288       412\n",
      "\n",
      "    accuracy                         0.7200       943\n",
      "   macro avg     0.7311    0.5883    0.5699       943\n",
      "weighted avg     0.7256    0.7200    0.6778       943\n",
      "\n",
      "--- 132.67969584465027 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features3000_analyzer_word.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7208    0.6283    0.6714       226\n",
      "           2     0.7259    0.7296    0.7277       196\n",
      "           3     0.6667    0.0183    0.0357       109\n",
      "           4     0.7216    0.9563    0.8225       412\n",
      "\n",
      "    accuracy                         0.7222       943\n",
      "   macro avg     0.7087    0.5831    0.5643       943\n",
      "weighted avg     0.7160    0.7222    0.6757       943\n",
      "\n",
      "--- 197.71748900413513 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features3000_analyzer_char.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7208    0.6283    0.6714       226\n",
      "           2     0.7259    0.7296    0.7277       196\n",
      "           3     0.6667    0.0183    0.0357       109\n",
      "           4     0.7216    0.9563    0.8225       412\n",
      "\n",
      "    accuracy                         0.7222       943\n",
      "   macro avg     0.7087    0.5831    0.5643       943\n",
      "weighted avg     0.7160    0.7222    0.6757       943\n",
      "\n",
      "--- 191.49762654304504 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features_None_analyzer_char.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6606    0.6372    0.6486       226\n",
      "           2     0.7192    0.7449    0.7318       196\n",
      "           3     0.8000    0.0367    0.0702       109\n",
      "           4     0.7447    0.9345    0.8288       412\n",
      "\n",
      "    accuracy                         0.7200       943\n",
      "   macro avg     0.7311    0.5883    0.5699       943\n",
      "weighted avg     0.7256    0.7200    0.6778       943\n",
      "\n",
      "--- 131.79243898391724 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features_None_analyzer_char_wb.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7208    0.6283    0.6714       226\n",
      "           2     0.7259    0.7296    0.7277       196\n",
      "           3     0.6667    0.0183    0.0357       109\n",
      "           4     0.7216    0.9563    0.8225       412\n",
      "\n",
      "    accuracy                         0.7222       943\n",
      "   macro avg     0.7087    0.5831    0.5643       943\n",
      "weighted avg     0.7160    0.7222    0.6757       943\n",
      "\n",
      "--- 192.6641674041748 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features_None_analyzer_word.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7208    0.6283    0.6714       226\n",
      "           2     0.7259    0.7296    0.7277       196\n",
      "           3     0.6667    0.0183    0.0357       109\n",
      "           4     0.7216    0.9563    0.8225       412\n",
      "\n",
      "    accuracy                         0.7222       943\n",
      "   macro avg     0.7087    0.5831    0.5643       943\n",
      "weighted avg     0.7160    0.7222    0.6757       943\n",
      "\n",
      "--- 193.53840279579163 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features_None_analyzer_char_wb.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6606    0.6372    0.6486       226\n",
      "           2     0.7192    0.7449    0.7318       196\n",
      "           3     0.8000    0.0367    0.0702       109\n",
      "           4     0.7447    0.9345    0.8288       412\n",
      "\n",
      "    accuracy                         0.7200       943\n",
      "   macro avg     0.7311    0.5883    0.5699       943\n",
      "weighted avg     0.7256    0.7200    0.6778       943\n",
      "\n",
      "--- 131.2805507183075 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features3000_analyzer_char.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6606    0.6372    0.6486       226\n",
      "           2     0.7192    0.7449    0.7318       196\n",
      "           3     0.8000    0.0367    0.0702       109\n",
      "           4     0.7447    0.9345    0.8288       412\n",
      "\n",
      "    accuracy                         0.7200       943\n",
      "   macro avg     0.7311    0.5883    0.5699       943\n",
      "weighted avg     0.7256    0.7200    0.6778       943\n",
      "\n",
      "--- 131.83905458450317 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features3000_analyzer_char_wb.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7208    0.6283    0.6714       226\n",
      "           2     0.7259    0.7296    0.7277       196\n",
      "           3     0.6667    0.0183    0.0357       109\n",
      "           4     0.7216    0.9563    0.8225       412\n",
      "\n",
      "    accuracy                         0.7222       943\n",
      "   macro avg     0.7087    0.5831    0.5643       943\n",
      "weighted avg     0.7160    0.7222    0.6757       943\n",
      "\n",
      "--- 193.2972092628479 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features_None_analyzer_char.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.7208    0.6283    0.6714       226\n",
      "           2     0.7259    0.7296    0.7277       196\n",
      "           3     0.6667    0.0183    0.0357       109\n",
      "           4     0.7216    0.9563    0.8225       412\n",
      "\n",
      "    accuracy                         0.7222       943\n",
      "   macro avg     0.7087    0.5831    0.5643       943\n",
      "weighted avg     0.7160    0.7222    0.6757       943\n",
      "\n",
      "--- 191.92705368995667 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features3000_analyzer_char_wb.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6606    0.6372    0.6486       226\n",
      "           2     0.7192    0.7449    0.7318       196\n",
      "           3     0.8000    0.0367    0.0702       109\n",
      "           4     0.7447    0.9345    0.8288       412\n",
      "\n",
      "    accuracy                         0.7200       943\n",
      "   macro avg     0.7311    0.5883    0.5699       943\n",
      "weighted avg     0.7256    0.7200    0.6778       943\n",
      "\n",
      "--- 131.86921572685242 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features3000_analyzer_word.pkl\n",
      "{'probability': True, 'kernel': 'linear', 'C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6606    0.6372    0.6486       226\n",
      "           2     0.7192    0.7449    0.7318       196\n",
      "           3     0.8000    0.0367    0.0702       109\n",
      "           4     0.7447    0.9345    0.8288       412\n",
      "\n",
      "    accuracy                         0.7200       943\n",
      "   macro avg     0.7311    0.5883    0.5699       943\n",
      "weighted avg     0.7256    0.7200    0.6778       943\n",
      "\n",
      "--- 131.64417147636414 seconds ---\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "idx=0\n",
    "df_linear=pd.DataFrame()\n",
    "\n",
    "for i in tfidf_paths:\n",
    "    print(i.split(\"/\")[-1])\n",
    "    start_time=time.time()\n",
    "    tfidf_vectorizer=pickle.load(open(i, \"rb\"))\n",
    "    X_train=tfidf_vectorizer.fit_transform(X_train_doc_list) \n",
    "    X_test=tfidf_vectorizer.transform(X_test_doc_list)\n",
    "    \n",
    "    C = [ .1,1,10,100]\n",
    "    probability = [True]\n",
    "\n",
    "    param_grid = [\n",
    "      {'C': C, 'kernel':['linear'], 'probability':probability}\n",
    "    ]\n",
    "    \n",
    "    # Create a base model\n",
    "    svc = svm.SVC(random_state=8)\n",
    "\n",
    "    # Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "    #cv_sets = ShuffleSplit(n_splits = 10, test_size = .13, random_state = 8)\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=svc, \n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=10,n_jobs=-1)\n",
    "\n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_svc = grid_search.best_estimator_\n",
    "    svc_pred = best_svc.predict(X_test)\n",
    "    print(grid_search.best_params_)\n",
    "    y_hat=grid_search.predict(X_test)\n",
    "    print(metrics.classification_report(y_test,y_hat,digits=4))\n",
    "    print(\"--- %s seconds ---\"%(time.time()-start_time))\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    #save in df\n",
    "    d = {\n",
    "     'Model': best_svc,\n",
    "     'Training Set Accuracy': accuracy_score(y_train, best_svc.predict(X_train)),\n",
    "     'Test Set Accuracy': accuracy_score(y_test, svc_pred),\n",
    "      'TF-IDF Model':tfidf_vectorizer,\n",
    "    'F1 score:':f1_score(y_test,  svc_pred, average = \"micro\")\n",
    "    }\n",
    "    df_linear=pd.concat([df_linear,pd.DataFrame(d, index=[idx])])\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_linear.to_csv(\"./df_linear.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score:</th>\n",
       "      <th>Model</th>\n",
       "      <th>TF-IDF Model</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.720042</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.720042</td>\n",
       "      <td>0.738323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.722163</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.722163</td>\n",
       "      <td>0.746815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.722163</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.722163</td>\n",
       "      <td>0.746815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.720042</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.720042</td>\n",
       "      <td>0.738323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.722163</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.722163</td>\n",
       "      <td>0.746815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.722163</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.722163</td>\n",
       "      <td>0.746815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.720042</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.720042</td>\n",
       "      <td>0.738323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.720042</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.720042</td>\n",
       "      <td>0.738323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.722163</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.722163</td>\n",
       "      <td>0.746815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.722163</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.722163</td>\n",
       "      <td>0.746815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.720042</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.720042</td>\n",
       "      <td>0.738323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.720042</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.720042</td>\n",
       "      <td>0.738323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F1 score:                                              Model  \\\n",
       "0    0.720042  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "1    0.722163  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "2    0.722163  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "3    0.720042  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "4    0.722163  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "5    0.722163  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "6    0.720042  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "7    0.720042  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "8    0.722163  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "9    0.722163  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "10   0.720042  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "11   0.720042  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "\n",
       "                                         TF-IDF Model  Test Set Accuracy  \\\n",
       "0   TfidfVectorizer(analyzer='word', binary=False,...           0.720042   \n",
       "1   TfidfVectorizer(analyzer='word', binary=False,...           0.722163   \n",
       "2   TfidfVectorizer(analyzer='word', binary=False,...           0.722163   \n",
       "3   TfidfVectorizer(analyzer='word', binary=False,...           0.720042   \n",
       "4   TfidfVectorizer(analyzer='word', binary=False,...           0.722163   \n",
       "5   TfidfVectorizer(analyzer='word', binary=False,...           0.722163   \n",
       "6   TfidfVectorizer(analyzer='word', binary=False,...           0.720042   \n",
       "7   TfidfVectorizer(analyzer='word', binary=False,...           0.720042   \n",
       "8   TfidfVectorizer(analyzer='word', binary=False,...           0.722163   \n",
       "9   TfidfVectorizer(analyzer='word', binary=False,...           0.722163   \n",
       "10  TfidfVectorizer(analyzer='word', binary=False,...           0.720042   \n",
       "11  TfidfVectorizer(analyzer='word', binary=False,...           0.720042   \n",
       "\n",
       "    Training Set Accuracy  \n",
       "0                0.738323  \n",
       "1                0.746815  \n",
       "2                0.746815  \n",
       "3                0.738323  \n",
       "4                0.746815  \n",
       "5                0.746815  \n",
       "6                0.738323  \n",
       "7                0.738323  \n",
       "8                0.746815  \n",
       "9                0.746815  \n",
       "10               0.738323  \n",
       "11               0.738323  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF SVM Testing CV=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_uni_features_None_analyzer_word.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6647    0.5000    0.5707       226\n",
      "           2     0.6777    0.4184    0.5174       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6120    0.9684    0.7500       412\n",
      "\n",
      "    accuracy                         0.6299       943\n",
      "   macro avg     0.4886    0.4717    0.4595       943\n",
      "weighted avg     0.5675    0.6299    0.5720       943\n",
      "\n",
      "--- 826.6347968578339 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features3000_analyzer_word.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 19.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6650    0.5796    0.6194       226\n",
      "           2     0.7156    0.3980    0.5115       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6248    0.9660    0.7588       412\n",
      "\n",
      "    accuracy                         0.6437       943\n",
      "   macro avg     0.5013    0.4859    0.4724       943\n",
      "weighted avg     0.5811    0.6437    0.5863       943\n",
      "\n",
      "--- 1209.2549617290497 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features3000_analyzer_char.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 19.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6650    0.5796    0.6194       226\n",
      "           2     0.7156    0.3980    0.5115       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6248    0.9660    0.7588       412\n",
      "\n",
      "    accuracy                         0.6437       943\n",
      "   macro avg     0.5013    0.4859    0.4724       943\n",
      "weighted avg     0.5811    0.6437    0.5863       943\n",
      "\n",
      "--- 1207.662192106247 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features_None_analyzer_char.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6647    0.5000    0.5707       226\n",
      "           2     0.6777    0.4184    0.5174       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6120    0.9684    0.7500       412\n",
      "\n",
      "    accuracy                         0.6299       943\n",
      "   macro avg     0.4886    0.4717    0.4595       943\n",
      "weighted avg     0.5675    0.6299    0.5720       943\n",
      "\n",
      "--- 825.8666794300079 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features_None_analyzer_char_wb.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 11.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 20.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6650    0.5796    0.6194       226\n",
      "           2     0.7156    0.3980    0.5115       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6248    0.9660    0.7588       412\n",
      "\n",
      "    accuracy                         0.6437       943\n",
      "   macro avg     0.5013    0.4859    0.4724       943\n",
      "weighted avg     0.5811    0.6437    0.5863       943\n",
      "\n",
      "--- 1238.3724365234375 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features_None_analyzer_word.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 11.7min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 19.8min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6650    0.5796    0.6194       226\n",
      "           2     0.7156    0.3980    0.5115       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6248    0.9660    0.7588       412\n",
      "\n",
      "    accuracy                         0.6437       943\n",
      "   macro avg     0.5013    0.4859    0.4724       943\n",
      "weighted avg     0.5811    0.6437    0.5863       943\n",
      "\n",
      "--- 1226.982842206955 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features_None_analyzer_char_wb.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6647    0.5000    0.5707       226\n",
      "           2     0.6777    0.4184    0.5174       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6120    0.9684    0.7500       412\n",
      "\n",
      "    accuracy                         0.6299       943\n",
      "   macro avg     0.4886    0.4717    0.4595       943\n",
      "weighted avg     0.5675    0.6299    0.5720       943\n",
      "\n",
      "--- 826.4509565830231 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features3000_analyzer_char.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 13.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6647    0.5000    0.5707       226\n",
      "           2     0.6777    0.4184    0.5174       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6120    0.9684    0.7500       412\n",
      "\n",
      "    accuracy                         0.6299       943\n",
      "   macro avg     0.4886    0.4717    0.4595       943\n",
      "weighted avg     0.5675    0.6299    0.5720       943\n",
      "\n",
      "--- 826.1149396896362 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features3000_analyzer_char_wb.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 19.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6650    0.5796    0.6194       226\n",
      "           2     0.7156    0.3980    0.5115       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6248    0.9660    0.7588       412\n",
      "\n",
      "    accuracy                         0.6437       943\n",
      "   macro avg     0.5013    0.4859    0.4724       943\n",
      "weighted avg     0.5811    0.6437    0.5863       943\n",
      "\n",
      "--- 1212.120670080185 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features_None_analyzer_char.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 11.6min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 19.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6650    0.5796    0.6194       226\n",
      "           2     0.7156    0.3980    0.5115       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6248    0.9660    0.7588       412\n",
      "\n",
      "    accuracy                         0.6437       943\n",
      "   macro avg     0.5013    0.4859    0.4724       943\n",
      "weighted avg     0.5811    0.6437    0.5863       943\n",
      "\n",
      "--- 1218.375580072403 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features3000_analyzer_char_wb.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6647    0.5000    0.5707       226\n",
      "           2     0.6777    0.4184    0.5174       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6120    0.9684    0.7500       412\n",
      "\n",
      "    accuracy                         0.6299       943\n",
      "   macro avg     0.4886    0.4717    0.4595       943\n",
      "weighted avg     0.5675    0.6299    0.5720       943\n",
      "\n",
      "--- 827.2475779056549 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features3000_analyzer_word.pkl\n",
      "Fitting 10 folds for each of 28 candidates, totalling 280 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  7.8min\n",
      "[Parallel(n_jobs=-1)]: Done 280 out of 280 | elapsed: 13.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'kernel': 'rbf', 'C': 0.1, 'gamma': 0.8}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.6647    0.5000    0.5707       226\n",
      "           2     0.6777    0.4184    0.5174       196\n",
      "           3     0.0000    0.0000    0.0000       109\n",
      "           4     0.6120    0.9684    0.7500       412\n",
      "\n",
      "    accuracy                         0.6299       943\n",
      "   macro avg     0.4886    0.4717    0.4595       943\n",
      "weighted avg     0.5675    0.6299    0.5720       943\n",
      "\n",
      "--- 830.7452862262726 seconds ---\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "df_rbf=pd.DataFrame()\n",
    "idx=0\n",
    "\n",
    "for i in tfidf_paths:\n",
    "    print(i.split(\"/\")[-1])\n",
    "    start_time=time.time()\n",
    "    tdidf_vectorizer=pickle.load(open(i, \"rb\"))\n",
    "    X_train=tdidf_vectorizer.fit_transform(X_train_doc_list) \n",
    "    X_test=tdidf_vectorizer.transform(X_test_doc_list)\n",
    "    \n",
    "    C = [ .1,1,10,100]\n",
    "    degree = [1,2,3, 4]\n",
    "    gamma = [0.6,0.8,1, 10]\n",
    "    probability = [True]\n",
    "    \n",
    "    param_grid = [\n",
    "          {'C': C, 'kernel':['rbf'],'gamma':gamma, 'probability':probability}\n",
    "    ]\n",
    "    \n",
    "\n",
    "    # Create a base model\n",
    "    svc = svm.SVC(random_state=8)\n",
    "\n",
    "    # Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "    #cv_sets = ShuffleSplit(n_splits = 10, test_size = .13, random_state = 8)\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=svc, \n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=10,\n",
    "                               verbose=1,n_jobs=-1)\n",
    "    \n",
    "    # Fit the grid search to the data\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_svc = grid_search.best_estimator_\n",
    "    svc_pred = best_svc.predict(X_test)\n",
    "    \n",
    "    print(grid_search.best_params_)\n",
    "    y_hat=grid_search.predict(X_test)\n",
    "    print(metrics.classification_report(y_test,y_hat,digits=4))\n",
    "    print(\"--- %s seconds ---\"%(time.time()-start_time))\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    d = {\n",
    "     'Model': best_svc,\n",
    "     'Training Set Accuracy': accuracy_score(y_train, best_svc.predict(X_train)),\n",
    "     'Test Set Accuracy': accuracy_score(y_test, svc_pred),\n",
    "      'TF-IDF Model':tfidf_vectorizer,\n",
    "     'F1 score:':f1_score(y_test,  svc_pred, average = \"macro\")\n",
    "    }\n",
    "    df_rbf=pd.concat([df_rbf,pd.DataFrame(d, index=[idx])])\n",
    "    idx+=1\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score:</th>\n",
       "      <th>Model</th>\n",
       "      <th>TF-IDF Model</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.459514</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.629905</td>\n",
       "      <td>0.653662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.472420</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.643690</td>\n",
       "      <td>0.670382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.472420</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.643690</td>\n",
       "      <td>0.670382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.459514</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.629905</td>\n",
       "      <td>0.653662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.472420</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.643690</td>\n",
       "      <td>0.670382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.472420</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.643690</td>\n",
       "      <td>0.670382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.459514</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.629905</td>\n",
       "      <td>0.653662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.459514</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.629905</td>\n",
       "      <td>0.653662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.472420</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.643690</td>\n",
       "      <td>0.670382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.472420</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.643690</td>\n",
       "      <td>0.670382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.459514</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.629905</td>\n",
       "      <td>0.653662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.459514</td>\n",
       "      <td>SVC(C=0.1, break_ties=False, cache_size=200, c...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.629905</td>\n",
       "      <td>0.653662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    F1 score:                                              Model  \\\n",
       "0    0.459514  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "1    0.472420  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "2    0.472420  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "3    0.459514  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "4    0.472420  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "5    0.472420  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "6    0.459514  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "7    0.459514  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "8    0.472420  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "9    0.472420  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "10   0.459514  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "11   0.459514  SVC(C=0.1, break_ties=False, cache_size=200, c...   \n",
       "\n",
       "                                         TF-IDF Model  Test Set Accuracy  \\\n",
       "0   TfidfVectorizer(analyzer='word', binary=False,...           0.629905   \n",
       "1   TfidfVectorizer(analyzer='word', binary=False,...           0.643690   \n",
       "2   TfidfVectorizer(analyzer='word', binary=False,...           0.643690   \n",
       "3   TfidfVectorizer(analyzer='word', binary=False,...           0.629905   \n",
       "4   TfidfVectorizer(analyzer='word', binary=False,...           0.643690   \n",
       "5   TfidfVectorizer(analyzer='word', binary=False,...           0.643690   \n",
       "6   TfidfVectorizer(analyzer='word', binary=False,...           0.629905   \n",
       "7   TfidfVectorizer(analyzer='word', binary=False,...           0.629905   \n",
       "8   TfidfVectorizer(analyzer='word', binary=False,...           0.643690   \n",
       "9   TfidfVectorizer(analyzer='word', binary=False,...           0.643690   \n",
       "10  TfidfVectorizer(analyzer='word', binary=False,...           0.629905   \n",
       "11  TfidfVectorizer(analyzer='word', binary=False,...           0.629905   \n",
       "\n",
       "    Training Set Accuracy  \n",
       "0                0.653662  \n",
       "1                0.670382  \n",
       "2                0.670382  \n",
       "3                0.653662  \n",
       "4                0.670382  \n",
       "5                0.670382  \n",
       "6                0.653662  \n",
       "7                0.653662  \n",
       "8                0.670382  \n",
       "9                0.670382  \n",
       "10               0.653662  \n",
       "11               0.653662  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rbf.to_csv(\"./df_rbf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polynomial SVM Testing CV=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfidf_uni_features_None_analyzer_word.pkl\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'degree': 2, 'kernel': 'poly', 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8802    0.8451    0.8623       226\n",
      "           2     0.8838    0.8929    0.8883       196\n",
      "           3     0.8191    0.7064    0.7586       109\n",
      "           4     0.8963    0.9442    0.9196       412\n",
      "\n",
      "    accuracy                         0.8823       943\n",
      "   macro avg     0.8699    0.8471    0.8572       943\n",
      "weighted avg     0.8809    0.8823    0.8808       943\n",
      "\n",
      "--- 605.1740169525146 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features3000_analyzer_word.pkl\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'degree': 2, 'kernel': 'poly', 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9140    0.8938    0.9038       226\n",
      "           2     0.8974    0.8929    0.8951       196\n",
      "           3     0.8280    0.7064    0.7624       109\n",
      "           4     0.9078    0.9563    0.9314       412\n",
      "\n",
      "    accuracy                         0.8993       943\n",
      "   macro avg     0.8868    0.8623    0.8732       943\n",
      "weighted avg     0.8979    0.8993    0.8977       943\n",
      "\n",
      "--- 901.5239033699036 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features_None_analyzer_char_wb.pkl\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 14.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'degree': 2, 'kernel': 'poly', 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9140    0.8938    0.9038       226\n",
      "           2     0.8974    0.8929    0.8951       196\n",
      "           3     0.8280    0.7064    0.7624       109\n",
      "           4     0.9078    0.9563    0.9314       412\n",
      "\n",
      "    accuracy                         0.8993       943\n",
      "   macro avg     0.8868    0.8623    0.8732       943\n",
      "weighted avg     0.8979    0.8993    0.8977       943\n",
      "\n",
      "--- 896.724276304245 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features_None_analyzer_word.pkl\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'degree': 2, 'kernel': 'poly', 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9140    0.8938    0.9038       226\n",
      "           2     0.8974    0.8929    0.8951       196\n",
      "           3     0.8280    0.7064    0.7624       109\n",
      "           4     0.9078    0.9563    0.9314       412\n",
      "\n",
      "    accuracy                         0.8993       943\n",
      "   macro avg     0.8868    0.8623    0.8732       943\n",
      "weighted avg     0.8979    0.8993    0.8977       943\n",
      "\n",
      "--- 898.8492918014526 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features_None_analyzer_char_wb.pkl\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'degree': 2, 'kernel': 'poly', 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8802    0.8451    0.8623       226\n",
      "           2     0.8838    0.8929    0.8883       196\n",
      "           3     0.8191    0.7064    0.7586       109\n",
      "           4     0.8963    0.9442    0.9196       412\n",
      "\n",
      "    accuracy                         0.8823       943\n",
      "   macro avg     0.8699    0.8471    0.8572       943\n",
      "weighted avg     0.8809    0.8823    0.8808       943\n",
      "\n",
      "--- 603.7625484466553 seconds ---\n",
      "----------------------------------\n",
      "tfidf_unibi_features3000_analyzer_char_wb.pkl\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed: 12.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed: 14.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'degree': 2, 'kernel': 'poly', 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.9140    0.8938    0.9038       226\n",
      "           2     0.8974    0.8929    0.8951       196\n",
      "           3     0.8280    0.7064    0.7624       109\n",
      "           4     0.9078    0.9563    0.9314       412\n",
      "\n",
      "    accuracy                         0.8993       943\n",
      "   macro avg     0.8868    0.8623    0.8732       943\n",
      "weighted avg     0.8979    0.8993    0.8977       943\n",
      "\n",
      "--- 899.0029284954071 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features3000_analyzer_char_wb.pkl\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'degree': 2, 'kernel': 'poly', 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8802    0.8451    0.8623       226\n",
      "           2     0.8838    0.8929    0.8883       196\n",
      "           3     0.8191    0.7064    0.7586       109\n",
      "           4     0.8963    0.9442    0.9196       412\n",
      "\n",
      "    accuracy                         0.8823       943\n",
      "   macro avg     0.8699    0.8471    0.8572       943\n",
      "weighted avg     0.8809    0.8823    0.8808       943\n",
      "\n",
      "--- 604.1910843849182 seconds ---\n",
      "----------------------------------\n",
      "tfidf_uni_features3000_analyzer_word.pkl\n",
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 168 tasks      | elapsed:  8.0min\n",
      "[Parallel(n_jobs=-1)]: Done 200 out of 200 | elapsed:  9.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'probability': True, 'degree': 2, 'kernel': 'poly', 'C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1     0.8802    0.8451    0.8623       226\n",
      "           2     0.8838    0.8929    0.8883       196\n",
      "           3     0.8191    0.7064    0.7586       109\n",
      "           4     0.8963    0.9442    0.9196       412\n",
      "\n",
      "    accuracy                         0.8823       943\n",
      "   macro avg     0.8699    0.8471    0.8572       943\n",
      "weighted avg     0.8809    0.8823    0.8808       943\n",
      "\n",
      "--- 603.7832071781158 seconds ---\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "df_poly=pd.DataFrame()\n",
    "idx=0\n",
    "for i in tfidf_paths:\n",
    "    print(i.split(\"/\")[-1])\n",
    "    start_time=time.time()\n",
    "    tdidf_vectorizer=pickle.load(open(i, \"rb\"))\n",
    "    X_train=tdidf_vectorizer.fit_transform(X_train_doc_list) \n",
    "    X_test=tdidf_vectorizer.transform(X_test_doc_list)\n",
    "    \n",
    "    C = [ .01, .1,1.,10]\n",
    "    degree = [1,2,3, 4, 5]\n",
    "    probability = [True]\n",
    "    \n",
    "\n",
    "    param_grid = [\n",
    "     \n",
    "      {'C': C, 'kernel':['poly'], 'degree':degree, 'probability':probability},\n",
    "   \n",
    "    ]\n",
    "\n",
    "    # Create a base model\n",
    "    svc = svm.SVC(random_state=8)\n",
    "\n",
    "    # Manually create the splits in CV in order to be able to fix a random_state (GridSearchCV doesn't have that argument)\n",
    "    #cv_sets = ShuffleSplit(n_splits = 10, test_size = .13, random_state = 8)\n",
    "\n",
    "    # Instantiate the grid search model\n",
    "    grid_search = GridSearchCV(estimator=svc, \n",
    "                               param_grid=param_grid,\n",
    "                               scoring='accuracy',\n",
    "                               cv=10,\n",
    "                               verbose=1,n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_svc = grid_search.best_estimator_\n",
    "    svc_pred = best_svc.predict(X_test)\n",
    "    \n",
    "    print(grid_search.best_params_)\n",
    "    y_hat=grid_search.predict(X_test)\n",
    "    print(metrics.classification_report(y_test,y_hat,digits=4))\n",
    "    print(\"--- %s seconds ---\"%(time.time()-start_time))\n",
    "    print(\"----------------------------------\")\n",
    "    \n",
    "    d = {\n",
    "     'Model': best_svc,\n",
    "     'Training Set Accuracy': accuracy_score(y_train, best_svc.predict(X_train)),\n",
    "     'Test Set Accuracy': accuracy_score(y_test, svc_pred),\n",
    "     'TF-IDF Model':tfidf_vectorizer,\n",
    "     'F1 score:':f1_score(y_test,  svc_pred, average = \"micro\")\n",
    "    }\n",
    "    df_poly=pd.concat([df_poly,pd.DataFrame(d, index=[idx])])\n",
    "    idx+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score:</th>\n",
       "      <th>Model</th>\n",
       "      <th>TF-IDF Model</th>\n",
       "      <th>Test Set Accuracy</th>\n",
       "      <th>Training Set Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.882291</td>\n",
       "      <td>SVC(C=10, break_ties=False, cache_size=200, cl...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.882291</td>\n",
       "      <td>0.994958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.899258</td>\n",
       "      <td>SVC(C=10, break_ties=False, cache_size=200, cl...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.899258</td>\n",
       "      <td>0.994692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.899258</td>\n",
       "      <td>SVC(C=10, break_ties=False, cache_size=200, cl...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.899258</td>\n",
       "      <td>0.994692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.899258</td>\n",
       "      <td>SVC(C=10, break_ties=False, cache_size=200, cl...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.899258</td>\n",
       "      <td>0.994692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.882291</td>\n",
       "      <td>SVC(C=10, break_ties=False, cache_size=200, cl...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.882291</td>\n",
       "      <td>0.994958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.899258</td>\n",
       "      <td>SVC(C=10, break_ties=False, cache_size=200, cl...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.899258</td>\n",
       "      <td>0.994692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.882291</td>\n",
       "      <td>SVC(C=10, break_ties=False, cache_size=200, cl...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.882291</td>\n",
       "      <td>0.994958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.882291</td>\n",
       "      <td>SVC(C=10, break_ties=False, cache_size=200, cl...</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>0.882291</td>\n",
       "      <td>0.994958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   F1 score:                                              Model  \\\n",
       "0   0.882291  SVC(C=10, break_ties=False, cache_size=200, cl...   \n",
       "1   0.899258  SVC(C=10, break_ties=False, cache_size=200, cl...   \n",
       "2   0.899258  SVC(C=10, break_ties=False, cache_size=200, cl...   \n",
       "3   0.899258  SVC(C=10, break_ties=False, cache_size=200, cl...   \n",
       "4   0.882291  SVC(C=10, break_ties=False, cache_size=200, cl...   \n",
       "5   0.899258  SVC(C=10, break_ties=False, cache_size=200, cl...   \n",
       "6   0.882291  SVC(C=10, break_ties=False, cache_size=200, cl...   \n",
       "7   0.882291  SVC(C=10, break_ties=False, cache_size=200, cl...   \n",
       "\n",
       "                                        TF-IDF Model  Test Set Accuracy  \\\n",
       "0  TfidfVectorizer(analyzer='word', binary=False,...           0.882291   \n",
       "1  TfidfVectorizer(analyzer='word', binary=False,...           0.899258   \n",
       "2  TfidfVectorizer(analyzer='word', binary=False,...           0.899258   \n",
       "3  TfidfVectorizer(analyzer='word', binary=False,...           0.899258   \n",
       "4  TfidfVectorizer(analyzer='word', binary=False,...           0.882291   \n",
       "5  TfidfVectorizer(analyzer='word', binary=False,...           0.899258   \n",
       "6  TfidfVectorizer(analyzer='word', binary=False,...           0.882291   \n",
       "7  TfidfVectorizer(analyzer='word', binary=False,...           0.882291   \n",
       "\n",
       "   Training Set Accuracy  \n",
       "0               0.994958  \n",
       "1               0.994692  \n",
       "2               0.994692  \n",
       "3               0.994692  \n",
       "4               0.994958  \n",
       "5               0.994692  \n",
       "6               0.994958  \n",
       "7               0.994958  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_poly.to_csv(\"./df_poly.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF-Linear SVM Testing CV=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', svm.SVC(kernel='linear',probability=True)),\n",
    "])\n",
    "\n",
    "param_grid=[{\"tfidf__min_df\": [0.05,0.03],\"tfidf__max_df\": [0.9,0.8],\"tfidf__max_features\": [None,3000],\"tfidf__analyzer\":[\"word\",  \"char_wb\",\"char\"],   \n",
    "\"tfidf__ngram_range\":[(1,1),(1,2)],'clf__C':[.1,1,10]}]\n",
    "\n",
    "vector=GridSearchCV(pipeline, param_grid,cv=10,verbose=1,n_jobs=-1)\n",
    "\n",
    "vector.fit(tfidf_features_train_doc_list,labels_train)\n",
    "y_pred=vector.predict(tfidf_features_test_doc_list)\n",
    "print(classification_report(labels_test, y_pred,digits=4))\n",
    "\n",
    "print(\"best params:\")\n",
    "print(vector.best_params_)\n",
    "\n",
    "print(\"best estimator:\")\n",
    "print(vector.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### results:\n",
    "                   precision    recall  f1-score   support\n",
    "\n",
    "               1     0.8472    0.8584    0.8527       226\n",
    "               2     0.8866    0.8776    0.8821       196\n",
    "               3     0.7727    0.7798    0.7763       109\n",
    "               4     0.9024    0.8981    0.9002       412\n",
    "\n",
    "       micro avg     0.8706    0.8706    0.8706       943\n",
    "       macro avg     0.8522    0.8535    0.8528       943\n",
    "    weighted avg     0.8709    0.8706    0.8707       943\n",
    "\n",
    "-best params:\n",
    "\n",
    "\n",
    "    {'tfidf__max_df': 0.8, 'clf__C': 10, 'tfidf__ngram_range': (1, 2), 'tfidf__analyzer': 'word', 'tfidf__min_df': 0.03}\n",
    "\n",
    "\n",
    "-best estimator:\n",
    "\n",
    "\n",
    "    Pipeline(memory=None,\n",
    "         steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
    "            dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
    "            lowercase=True, max_df=0.8, max_features=None, min_df=0.03,\n",
    "            ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf...ar', max_iter=-1, probability=True, random_state=None,\n",
    "      shrinking=True, tol=0.001, verbose=False))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF-RBF SVM Testing CV=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', svm.SVC(kernel='rbf',probability=True)),\n",
    "])\n",
    "\n",
    "param_grid=[{\"tfidf__min_df\": [0.05],\"tfidf__max_df\": [0.9],\"tfidf__max_features\": [None,3000],   \n",
    "\"tfidf__ngram_range\":[(1,1),(1,2)],'clf__C':[.001,.01,.1],'clf__gamma':[1e-1,1, 10]}]\n",
    "\n",
    "\n",
    "ngram_dict={(1,1):\"uni\",(1,2):\"unibi\",(2,2):\"bi\"}\n",
    "\n",
    "vector=GridSearchCV(pipeline, param_grid,cv=10,verbose=1,n_jobs=-1)\n",
    "\n",
    "vector.fit(tfidf_features_train_doc_list,labels_train)\n",
    "y_pred=vector.predict(tfidf_features_test_doc_list)\n",
    "print(classification_report(labels_test, y_pred,digits=4))\n",
    "\n",
    "print(\"best params:\")\n",
    "print(vector.best_params_)\n",
    "\n",
    "print(\"best estimator:\")\n",
    "print(vector.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### results:\n",
    "\n",
    "                  precision    recall  f1-score   support\n",
    "\n",
    "               1     0.9238    0.8584    0.8899       226\n",
    "               2     0.9032    0.8571    0.8796       196\n",
    "               3     0.8095    0.7798    0.7944       109\n",
    "               4     0.8891    0.9539    0.9204       412\n",
    "\n",
    "       micro avg     0.8908    0.8908    0.8908       943\n",
    "       macro avg     0.8814    0.8623    0.8711       943\n",
    "    weighted avg     0.8912    0.8908    0.8900       943\n",
    "\n",
    "- best params:\n",
    "\n",
    "\n",
    "       {'clf__gamma': 0.8, 'tfidf__max_df': 0.9, 'clf__C': 10, 'tfidf__ngram_range': (1, 2), 'tfidf__min_df': 0.03}\n",
    "\n",
    "\n",
    "- best estimator:\n",
    "\n",
    "\n",
    "        Pipeline(memory=None,\n",
    "             steps=[('tfidf', TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
    "                dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
    "                lowercase=True, max_df=0.9, max_features=None, min_df=0.03,\n",
    "                ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_id...',\n",
    "          max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "          tol=0.001, verbose=False))])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TFIDF-Polynomial SVM CV=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', svm.SVC(kernel='poly',probability=True,gamma='auto')),\n",
    "])\n",
    "\n",
    "param_grid=[{\"tfidf__min_df\": [0.05],\"tfidf__max_df\": [0.9],\"tfidf__max_features\": [None,3000],\n",
    "             \"tfidf__analyzer\":[\"word\",  \"char_wb\",\"char\"], \"tfidf__ngram_range\":[(1,1),(1,2)],\n",
    "             'clf__C':[.001,.01,.1],'clf__degree':[1,3,5]}]\n",
    "\n",
    "\n",
    "ngram_dict={(1,1):\"uni\",(1,2):\"unibi\",(2,2):\"bi\"}\n",
    "\n",
    "vector=GridSearchCV(pipeline, param_grid,cv=10,scoring='accuracy',verbose=1,n_jobs=-1)\n",
    "\n",
    "vector.fit(tfidf_features_train_doc_list,labels_train)\n",
    "y_pred=vector.predict(tfidf_features_test_doc_list)\n",
    "print(classification_report(labels_test, y_pred,digits=4))\n",
    "\n",
    "print(\"best params:\")\n",
    "print(vector.best_params_)\n",
    "\n",
    "print(\"best estimator:\")\n",
    "print(vector.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results:\n",
    "\n",
    "                   precision    recall  f1-score   support\n",
    "\n",
    "               1     0.5882    0.4425    0.5051       226\n",
    "               2     0.0000    0.0000    0.0000       196\n",
    "               3     0.0000    0.0000    0.0000       109\n",
    "               4     0.5071    0.9515    0.6616       412\n",
    "\n",
    "       micro avg     0.5217    0.5217    0.5217       943\n",
    "       macro avg     0.2738    0.3485    0.2917       943\n",
    "    weighted avg     0.3625    0.5217    0.4101       943\n",
    "\n",
    "-best params:\n",
    "\n",
    "\n",
    "    {'tfidf__ngram_range': (1, 2), 'clf__C': 10.0, 'tfidf__max_features': None, 'tfidf__max_df': 0.9, 'tfidf__analyzer': 'word', 'tfidf__min_df': 0.05, 'clf__degree': 1}\n",
    "\n",
    "\n",
    "-best estimator:\n",
    "\n",
    "\n",
    "    Pipeline(memory=None,\n",
    "         steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error=u'strict',\n",
    "            dtype=<type 'numpy.float64'>, encoding=u'utf-8', input=u'content',\n",
    "            lowercase=True, max_df=0.9, max_features=None, min_df=0.05,\n",
    "            ngram_range=(1, 2), norm=u'l2', preprocessor=None, smooth_idf...',\n",
    "      max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "      tol=0.001, verbose=False))])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
